{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f4106f3-59eb-4bca-a2db-39dc9229aeeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eldhoittangeorge/opt/anaconda3/envs/ds/lib/python3.8/site-packages/ray/autoscaler/_private/cli_logger.py:57: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from haystack.utils import  convert_files_to_dicts, print_answers\n",
    "from haystack.nodes import FARMReader\n",
    "from haystack.document_stores import FAISSDocumentStore\n",
    "from haystack.nodes import DensePassageRetriever\n",
    "from haystack.pipelines import ExtractiveQAPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e653ab83-6aaa-4668-af5e-a3803b0c9f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_store = FAISSDocumentStore(faiss_index_factory_str=\"Flat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92bbba28-e9cc-4b39-abc4-f650336871cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# doc_dir = \"Data/article_txt_got\"\n",
    "# s3_url = \"https://s3.eu-central-1.amazonaws.com/deepset.ai-farm-qa/datasets/documents/wiki_gameofthrones_txt.zip\"\n",
    "# fetch_archive_from_http(url=s3_url, output_dir=doc_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f3274c-9bcc-4b61-b8b5-e211d8052913",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_dir = \"../../Site Data/Data\"\n",
    "dicts = convert_files_to_dicts(dir_path=doc_dir,split_paragraphs=True)\n",
    "document_store.write_documents(dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1941e398-fc1c-4d7b-821f-d8d379b651bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.modeling.utils -  Using devices: CPU\n",
      "INFO - haystack.modeling.utils -  Number of GPUs: 0\n",
      "Downloading: 100%|██████████| 232k/232k [00:16<00:00, 13.8kB/s] \n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Connection error, and we cannot find the requested files in the cached path. Please try again or make sure your Internet connection is on.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-13705e309eba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m retriever = DensePassageRetriever(document_store=document_store,\n\u001b[0m\u001b[1;32m      2\u001b[0m                                  \u001b[0mquery_embedding_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'facebook/dpr-question_encoder-single-nq-base'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                                  \u001b[0mpassage_embedding_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'facebook/dpr-ctx_encoder-single-nq-base'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                  \u001b[0mmax_seq_len_query\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                  \u001b[0mmax_seq_len_passage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/ds/lib/python3.8/site-packages/haystack/nodes/retriever/dense.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, document_store, query_embedding_model, passage_embedding_model, model_version, max_seq_len_query, max_seq_len_passage, top_k, use_gpu, batch_size, embed_title, use_fast_tokenizers, infer_tokenizer_classes, similarity_function, global_loss_buffer_size, progress_bar, devices, use_auth_token)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0;31m# Init & Load Encoders\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m         self.query_tokenizer = Tokenizer.load(pretrained_model_name_or_path=query_embedding_model,\n\u001b[0m\u001b[1;32m    152\u001b[0m                                               \u001b[0mrevision\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_version\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m                                               \u001b[0mdo_lower_case\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/ds/lib/python3.8/site-packages/haystack/modeling/model/tokenization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(cls, pretrained_model_name_or_path, revision, tokenizer_class, use_fast, use_auth_token, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;34m\"DPRQuestionEncoderTokenizer\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokenizer_class\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0muse_fast\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m                 \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDPRQuestionEncoderTokenizerFast\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_auth_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_auth_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m                 \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDPRQuestionEncoderTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_auth_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_auth_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/ds/lib/python3.8/site-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *init_inputs, **kwargs)\u001b[0m\n\u001b[1;32m   1670\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1671\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1672\u001b[0;31m                     resolved_vocab_files[file_id] = cached_path(\n\u001b[0m\u001b[1;32m   1673\u001b[0m                         \u001b[0mfile_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1674\u001b[0m                         \u001b[0mcache_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcache_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/ds/lib/python3.8/site-packages/transformers/file_utils.py\u001b[0m in \u001b[0;36mcached_path\u001b[0;34m(url_or_filename, cache_dir, force_download, proxies, resume_download, user_agent, extract_compressed_file, force_extract, use_auth_token, local_files_only)\u001b[0m\n\u001b[1;32m   1327\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_remote_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl_or_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1328\u001b[0m         \u001b[0;31m# URL, so get it from the cache (downloading if necessary)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1329\u001b[0;31m         output_path = get_from_cache(\n\u001b[0m\u001b[1;32m   1330\u001b[0m             \u001b[0murl_or_filename\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1331\u001b[0m             \u001b[0mcache_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcache_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/ds/lib/python3.8/site-packages/transformers/file_utils.py\u001b[0m in \u001b[0;36mget_from_cache\u001b[0;34m(url, cache_dir, force_download, proxies, etag_timeout, resume_download, user_agent, use_auth_token, local_files_only)\u001b[0m\n\u001b[1;32m   1550\u001b[0m                     )\n\u001b[1;32m   1551\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1552\u001b[0;31m                     raise ValueError(\n\u001b[0m\u001b[1;32m   1553\u001b[0m                         \u001b[0;34m\"Connection error, and we cannot find the requested files in the cached path.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1554\u001b[0m                         \u001b[0;34m\" Please try again or make sure your Internet connection is on.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Connection error, and we cannot find the requested files in the cached path. Please try again or make sure your Internet connection is on."
     ]
    }
   ],
   "source": [
    "retriever = DensePassageRetriever(document_store=document_store,\n",
    "                                 query_embedding_model='facebook/dpr-question_encoder-single-nq-base',\n",
    "                                 passage_embedding_model='facebook/dpr-ctx_encoder-single-nq-base',\n",
    "                                 max_seq_len_query=64,\n",
    "                                 max_seq_len_passage=256,\n",
    "                                 batch_size=16,\n",
    "                                 use_gpu=True,\n",
    "                                 embed_title=True,\n",
    "                                 use_fast_tokenizers=True)\n",
    "document_store.update_embeddings(retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2520b4d4-ff21-4f9c-a191-7229b2af50c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = FARMReader(model_name_or_path=\"deepset/roberta-base-squad2\", use_gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd7553e-be25-4404-9e39-9d031906c7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = ExtractiveQAPipeline(reader, retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f2c158d7-60fe-4a55-b538-297006471965",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inferencing Samples: 100%|██████████| 1/1 [00:12<00:00, 12.25s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.40 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.40 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.41 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.40 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.40 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:05<00:00,  5.19s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:10<00:00, 10.53s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:01<00:00,  1.35s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.40 Batches/s]\n"
     ]
    }
   ],
   "source": [
    "prediction = pipeline.run(query=\"Where is mits located?\",\n",
    "                         params = {\"Retriever\":{\"top_k\":10}, \n",
    "                                  \"Reader\":{\"top_k\":10}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "56baff09-7411-4408-a768-2c42e8d97912",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query: Where is mits located?\n",
      "Answers:\n",
      "[   {   'answer': 'Ernakulam',\n",
      "        'context': 'ering (CSE) at the Muthoot Institute of Technology and '\n",
      "                   'Science (MITS), Ernakulam! As you glance through the '\n",
      "                   'faculty profile, I am sure that you will a'},\n",
      "    {   'answer': 'Puthencruz',\n",
      "        'context': 'Department profile Muthoot Institute of Technology and '\n",
      "                   'Science (MITS) Puthencruz was established in May 2013 and '\n",
      "                   'started its academic program in Augus'},\n",
      "    {   'answer': 'Kochi',\n",
      "        'context': 'pal Muthoot Institute of Technology & Science Varikoli '\n",
      "                   'P.O., Puthencruz, Kochi – 682308, Ernakulam District. Ph. '\n",
      "                   '0484 – 2732100, 2732111, 2733011 Fax:'},\n",
      "    {   'answer': 'Varikoli overlooking the Kochi-Madurai National Highway',\n",
      "        'context': '7 kms from the MITS Campus. MITS is situated at Varikoli '\n",
      "                   'overlooking the Kochi-Madurai National Highway about 5 kms '\n",
      "                   'from Thiruvankulam en-route to Kol'},\n",
      "    {   'answer': 'of',\n",
      "        'context': 'Centres of Excellence at MITS Our major recruiters'},\n",
      "    {   'answer': 'Mahatma Gandhi University',\n",
      "        'context': 'hile preparing them for their undergraduate examinations '\n",
      "                   'under Mahatma Gandhi University and APJ Abdul Kalam '\n",
      "                   'Technological University. It helps studen'},\n",
      "    {   'answer': 'Kochi',\n",
      "        'context': 'om your goal. Archana Venugopal (CSE 2015-19) Tata '\n",
      "                   'Consultancy Services, Kochi News & Events Congratulations '\n",
      "                   'to Krishnapriya S. of CSE 2018-2022 Batch'},\n",
      "    {   'answer': 'India',\n",
      "        'context': 'in MITS. I have been placed in the three leading IT '\n",
      "                   'service companies in India which includes TCS,Infosys and '\n",
      "                   'Cognizant.This was possible only because'},\n",
      "    {   'answer': 'among stones',\n",
      "        'context': 'ed to us by our amazing faculty. The EEE Dept of MITS is '\n",
      "                   'truly a gem among stones. Gallery News & Events '\n",
      "                   'Congratulations to Jerin P Joy and Sivakarthi'},\n",
      "    {   'answer': 'Kerala',\n",
      "        'context': 'lar Power plant. This is one of its kind in educational '\n",
      "                   'Institutions of Kerala and will provide first-hand '\n",
      "                   'experience to the students from the departm'}]\n"
     ]
    }
   ],
   "source": [
    "print_answers(prediction,details=\"minimum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186a2a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving the models\n",
    "retriever.save(\"context_model_retriever\")\n",
    "document_store.save(\"model\")\n",
    "# document_store.save(\"context_model_store.faiss\")\n",
    "\n",
    "doc_tmp = FAISSDocumentStore.load(\"model\")\n",
    "ret_tmp  = DensePassageRetriever.load(\"context_model_retriever\",doc_tmp)\n",
    "\n",
    "document_store.save(\"model\")\n",
    "doc_tmp = FAISSDocumentStore.load(\"model\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ba8a2f979b76317ccf93e467e94d1dd25a4d448df8fe3a724a905e71adb08bc7"
  },
  "kernelspec": {
   "display_name": "default:Python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
