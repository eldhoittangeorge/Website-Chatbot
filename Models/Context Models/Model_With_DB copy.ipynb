{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ANT-PC\\anaconda3\\envs\\ds\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "INFO - haystack.document_stores.base -  Numba not found, replacing njit() with no-op implementation. Enable it with 'pip install numba'.\n",
      "INFO - haystack.modeling.model.optimization -  apex not found, won't use it. See https://nvidia.github.io/apex/\n",
      "ERROR - root -  Failed to import 'magic' (from 'python-magic' and 'python-magic-bin' on Windows). FileTypeClassifier will not perform mimetype detection on extensionless files. Please make sure the necessary OS libraries are installed if you need this functionality.\n"
     ]
    }
   ],
   "source": [
    "from pymongo import MongoClient\n",
    "from transformers import AutoModelForQuestionAnswering, AutoTokenizer, pipeline\n",
    "from haystack.schema import Document\n",
    "from sentence_transformers import SentenceTransformer,CrossEncoder, util\n",
    "from nltk import ngrams\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "db_client = MongoClient(host=\"localhost\", port=27017)\n",
    "database = db_client['Website_Chatbot']\n",
    "collection = database[\"MITS\"]\n",
    "\n",
    "model_name = \"deepset/roberta-base-squad2\"\n",
    "\n",
    "retriever_model = SentenceTransformer('multi-qa-MiniLM-L6-cos-v1')\n",
    "retriever_model.max_seq_length = 256\n",
    "cross_encoder = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2')\n",
    "\n",
    "\n",
    "reader_model = AutoModelForQuestionAnswering.from_pretrained(model_name)\n",
    "reader_tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [] \n",
    "for document in collection.find({}):\n",
    "    content = document[\"content\"].split()\n",
    "    # print(\" \".join([content[0+i : 256+i] for i in range(0, len(content), 256)]))\n",
    "    for i in range(0, len(content), 256):\n",
    "        docs.append(\" \".join(content[i: 256+i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 4/4 [00:00<00:00,  9.55it/s]\n"
     ]
    }
   ],
   "source": [
    "query = \"What is eco club\"\n",
    "query_embedding = retriever_model.encode(query.lower(), convert_to_tensor=True)\n",
    "document_embedding = retriever_model.encode(docs, convert_to_tensor=True, show_progress_bar=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = util.semantic_search(query_embedding, document_embedding, top_k=5)\n",
    "# best_para = np.argmax(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'corpus_id': 12, 'score': 0.7706955671310425},\n",
       "  {'corpus_id': 13, 'score': 0.5434941053390503},\n",
       "  {'corpus_id': 100, 'score': 0.4028398394584656},\n",
       "  {'corpus_id': 77, 'score': 0.36827030777931213},\n",
       "  {'corpus_id': 87, 'score': 0.35861924290657043}]]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_inp = [[query, docs[hit['corpus_id']]] for hit in score[0]]\n",
    "cross_scores = cross_encoder.predict(cross_inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 0.010533596388995647,\n",
       " 'start': 1293,\n",
       " 'end': 1303,\n",
       " 'answer': 'illuminati'}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp = pipeline(\"question-answering\", model = reader_model, tokenizer = reader_tokenizer)\n",
    "\n",
    "qa_input = {\"question\":query, \n",
    "\"context\":docs[77]}\n",
    "\n",
    "result = nlp(qa_input)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.55 Batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query: Who is the principal of MITS\n",
      "Answers:\n",
      "[   <Answer {'answer': 'Dr Chikku Abraham', 'type': 'extractive', 'score': 0.6559404730796814, 'context': 'llege Executive Director Mr.P George Varghese, the acting Pricipal Dr Chikku Abraham and the HODs of various departments were the dignitaries on the d', 'offsets_in_document': [{'start': 3880, 'end': 3897}], 'offsets_in_context': [{'start': 67, 'end': 84}], 'document_id': '6213cd02abf8a36f04f5c6d4', 'meta': {'source': 'http://mgmits.ac.in/life-mits/sports/', 'vector_id': '32'}}>,\n",
      "    <Answer {'answer': 'Dr Chikku Abraham', 'type': 'extractive', 'score': 0.20968271791934967, 'context': 'Vice Principal Muthoot Institute of Technology and Science (MITS) Dr Chikku Abraham is currently the Vice- Principal and Associate Professor in Electr', 'offsets_in_document': [{'start': 66, 'end': 83}], 'offsets_in_context': [{'start': 66, 'end': 83}], 'document_id': '6213cd07abf8a36f04f5c750', 'meta': {'source': 'http://mgmits.ac.in/mits/executive-body/vice-principal/', 'vector_id': '93'}}>,\n",
      "    <Answer {'answer': 'Mr. George Alexander Muthoot', 'type': 'extractive', 'score': 0.08442884683609009, 'context': 's furnished with synthetic playing surface. Muthoot group MD Mr. George Alexander Muthoot inaugurated the indoor court on 12-01-2022. The inaugural ev', 'offsets_in_document': [{'start': 1841, 'end': 1869}], 'offsets_in_context': [{'start': 61, 'end': 89}], 'document_id': '6213cd02abf8a36f04f5c6d4', 'meta': {'source': 'http://mgmits.ac.in/life-mits/sports/', 'vector_id': '32'}}>,\n",
      "    <Answer {'answer': 'Mr. Anish P Rajan', 'type': 'extractive', 'score': 0.06417724303901196, 'context': 'he year 2019-’20, ‘SPARK 2K20’ has conducted on 25th January 2020. Mr. Anish P Rajan, member of Indian Cricket team for physicallychallenged was the c', 'offsets_in_document': [{'start': 2703, 'end': 2720}], 'offsets_in_context': [{'start': 67, 'end': 84}], 'document_id': '6213cd02abf8a36f04f5c6d4', 'meta': {'source': 'http://mgmits.ac.in/life-mits/sports/', 'vector_id': '32'}}>,\n",
      "    <Answer {'answer': 'Dr Abhilash Antony', 'type': 'extractive', 'score': 0.04530875198543072, 'context': 'mbursement of fee for presenting papers/attending conferences. 1. Dr Abhilash Antony -Faculty Chairman R&C (Asso.Professor -ECE) 2. Dr Rajesh Cherian ', 'offsets_in_document': [{'start': 1239, 'end': 1257}], 'offsets_in_context': [{'start': 66, 'end': 84}], 'document_id': '6213ccffabf8a36f04f5c693', 'meta': {'source': 'http://mgmits.ac.in/research/research-and-consultancy-cell/', 'vector_id': '0'}}>,\n",
      "    <Answer {'answer': 'Dr Gylson Thomas', 'type': 'extractive', 'score': 0.02031051553785801, 'context': 'CONTINUING EDUCATION CELL (CEC-MITS) Dr Gylson Thomas, Faculty-in-charge Continuing Education Cell, MITS For more information, please click Our major ', 'offsets_in_document': [{'start': 37, 'end': 53}], 'offsets_in_context': [{'start': 37, 'end': 53}], 'document_id': '6213cd03abf8a36f04f5c6f4', 'meta': {'source': 'http://mgmits.ac.in/research/continuing-education-cell/', 'vector_id': '48'}}>,\n",
      "    <Answer {'answer': 'ian Roy', 'type': 'extractive', 'score': 0.002832058467902243, 'context': 'ash Antony -Faculty Chairman R&C (Asso.Professor -ECE) 2. Dr Rajesh Cherian Roy(Professor-CSE) 3. Dr Renju Rajan -Secretary (Asst.Professor-BS&H) 4. M', 'offsets_in_document': [{'start': 1319, 'end': 1326}], 'offsets_in_context': [{'start': 72, 'end': 79}], 'document_id': '6213ccffabf8a36f04f5c693', 'meta': {'source': 'http://mgmits.ac.in/research/research-and-consultancy-cell/', 'vector_id': '0'}}>,\n",
      "    <Answer {'answer': 'Prof. Dr. Ashwin', 'type': 'extractive', 'score': 0.002172774344217032, 'context': 'ces, seminars and symposia of mutual interest to the institutions. Prof. Dr. Ashwin, faculty, GSU, USA interacts with ECE faculty Prof. Dr. Ashwin, fa', 'offsets_in_document': [{'start': 1048, 'end': 1064}], 'offsets_in_context': [{'start': 67, 'end': 83}], 'document_id': '6213cd06abf8a36f04f5c72d', 'meta': {'source': 'http://mgmits.ac.in/gsu/', 'vector_id': '76'}}>,\n",
      "    <Answer {'answer': 'Shri. Vinod Tharakan', 'type': 'extractive', 'score': 0.0018105313065461814, 'context': 'Part 1 (full) : Lecture 1 – Shri. Vinod Tharakan, CEO, Claysys : Lecture 2 – Shri. M. M. Murugappan, Chairman, Murugappa Group : Lecture 3 – Shri. G. ', 'offsets_in_document': [{'start': 28, 'end': 48}], 'offsets_in_context': [{'start': 28, 'end': 48}], 'document_id': '6213cd02abf8a36f04f5c6e6', 'meta': {'source': 'http://mgmits.ac.in/life-mits/distinguished-lectures/', 'vector_id': '41'}}>,\n",
      "    <Answer {'answer': 'Performer', 'type': 'extractive', 'score': 0.0013735965476371348, 'context': 'g of Institutions on Innovation Achievement (ARIIA) 2021, in the band “Performer” under the category “Colleges /Institutes (Private/Self Financed) (Te', 'offsets_in_document': [{'start': 110, 'end': 119}], 'offsets_in_context': [{'start': 71, 'end': 80}], 'document_id': '6213cd01abf8a36f04f5c6c2', 'meta': {'source': 'http://mgmits.ac.in/news-general/mits-has-been-recognised-in-ariia-2021-in-the-band-performer-under-the-category-colleges-institutes-private-self-financed-technical/', 'vector_id': '23'}}>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "prediction = pipeline.run(query=\"Who is the principal of MITS\",\n",
    "                         params = {\"Retriever\":{\"top_k\":10}, \n",
    "                                  \"Reader\":{\"top_k\":10}})\n",
    "\n",
    "print_answers(prediction)                                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.modeling.model.biadaptive_model -  prediction_head saving\n"
     ]
    }
   ],
   "source": [
    "retriever.save(\"context_model_retriever_2\")\n",
    "document_store.save(\"document_store\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.modeling.utils -  Using devices: CUDA\n",
      "INFO - haystack.modeling.utils -  Number of GPUs: 1\n",
      "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
      "INFO - haystack.modeling.model.language_model -  =============\n",
      "INFO - haystack.modeling.model.language_model -  Model found locally at Saved Models/roberta_base_squad2\n",
      "INFO - haystack.modeling.model.language_model -  Loaded Saved Models/roberta_base_squad2\n",
      "INFO - haystack.modeling.model.adaptive_model -  Found files for loading 1 prediction heads\n",
      "WARNING - haystack.modeling.model.prediction_head -  Some unused parameters are passed to the QuestionAnsweringHead. Might not be a problem. Params: {\"training\": false, \"num_labels\": 2, \"ph_output_type\": \"per_token_squad\", \"model_type\": \"span_classification\", \"label_tensor_name\": \"question_answering_label_ids\", \"label_list\": [\"start_token\", \"end_token\"], \"metric\": \"squad\", \"name\": \"QuestionAnsweringHead\"}\n",
      "INFO - haystack.modeling.model.prediction_head -  Loading prediction head from Saved Models\\roberta_base_squad2\\prediction_head_0.bin\n",
      "INFO - haystack.modeling.data_handler.processor -  Initialized processor without tasks. Supply `metric` and `label_list` to the constructor for using the default task or add a custom task later via processor.add_task()\n",
      "INFO - haystack.modeling.logger -  ML Logging is turned off. No parameters, metrics or artifacts will be logged to MLFlow.\n",
      "INFO - haystack.modeling.utils -  Using devices: CUDA\n",
      "INFO - haystack.modeling.utils -  Number of GPUs: 1\n",
      "INFO - haystack.modeling.utils -  Using devices: CUDA:0\n",
      "INFO - haystack.modeling.utils -  Number of GPUs: 1\n",
      "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
      "INFO - haystack.modeling.model.language_model -  =============\n",
      "INFO - haystack.modeling.model.language_model -  Model found locally at context_model_retriever_2\\query_encoder\n",
      "INFO - haystack.modeling.model.language_model -  Loaded context_model_retriever_2\\query_encoder\n",
      "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
      "INFO - haystack.modeling.model.language_model -  =============\n",
      "INFO - haystack.modeling.model.language_model -  Model found locally at context_model_retriever_2\\passage_encoder\n",
      "INFO - haystack.modeling.model.language_model -  Loaded context_model_retriever_2\\passage_encoder\n",
      "INFO - haystack.nodes.retriever.dense -  DPR model loaded from context_model_retriever_2\n"
     ]
    }
   ],
   "source": [
    "tmp_doc_store = FAISSDocumentStore.load(\"document_store\")\n",
    "tmp_reader = FARMReader(model_name_or_path=\"Saved Models/roberta_base_squad2\",\n",
    "use_gpu=True, num_processes=0)\n",
    "tmp_retriever = DensePassageRetriever.load(\"context_model_retriever_2\", tmp_doc_store)\n",
    "tmp_pipeline = ExtractiveQAPipeline(tmp_reader, tmp_retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inferencing Samples:   0%|          | 0/1 [00:00<?, ? Batches/s]C:\\Users\\ANT-PC\\anaconda3\\envs\\ds\\lib\\site-packages\\haystack\\modeling\\model\\prediction_head.py:462: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  start_indices = flat_sorted_indices // max_seq_len\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:01<00:00,  1.26s/ Batches]\n"
     ]
    }
   ],
   "source": [
    "predictions = tmp_pipeline.run(\"Where is MITS located\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = predictions[\"answers\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'6213cd05abf8a36f04f5c720'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers[0].document_id"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "216b33ba287e42d2a87342f3b9e368cf1b71a9244e6603550934e59b39d7eb84"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 ('ds')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
